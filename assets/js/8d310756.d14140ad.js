"use strict";(self.webpackChunkhcihub_docs=self.webpackChunkhcihub_docs||[]).push([[9313],{895:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"datasets/non-invasive/EEGMMI","title":"3_EEGMMI","description":"Link to the dataset used:","source":"@site/docs/datasets/non-invasive/3_EEGMMI.md","sourceDirName":"datasets/non-invasive","slug":"/datasets/non-invasive/EEGMMI","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/EEGMMI","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/datasets/non-invasive/3_EEGMMI.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"2_GOD","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/GOD"},"next":{"title":"4_SEED IV","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/SEED IV"}}');var r=s(4848),a=s(8453);const o={},i="3_EEGMMI",d={},l=[{value:"Link to the dataset used:",id:"link-to-the-dataset-used",level:2},{value:"1. Project Overview",id:"1-project-overview",level:2},{value:"2.  Preprocessing Process",id:"2--preprocessing-process",level:2},{value:"3. Core Functions",id:"3-core-functions",level:2},{value:"3.1 load_data()",id:"31-load_data",level:4},{value:"4. Usage",id:"4-usage",level:2},{value:"4.1 Preparing  Data",id:"41-preparing--data",level:3},{value:"4.2 Running the preprocessing function &quot;load_data()&quot;",id:"42-running-the-preprocessing-function-load_data",level:3},{value:"4.3 Results Preview",id:"43-results-preview",level:3},{value:"4.4 Load the preprocessed data",id:"44-load-the-preprocessed-data",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"3_eegmmi",children:"3_EEGMMI"})}),"\n",(0,r.jsx)(n.h1,{id:"data-overview-and-processing-pipeline",children:"Data Overview and Processing Pipeline"}),"\n",(0,r.jsx)(n.h2,{id:"link-to-the-dataset-used",children:"Link to the dataset used:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://physionet.org/content/eegmmidb/1.0.0/",children:"https://physionet.org/content/eegmmidb/1.0.0/"})}),"\n",(0,r.jsx)(n.h2,{id:"1-project-overview",children:"1. Project Overview"}),"\n",(0,r.jsx)(n.p,{children:"This project provides a way to preprocess the EEG Motor Movement/Imagery dataset by transforming raw EEG signals into signals for model training. Only two subsets of the EEG Motor Movement/Imagery dataset were used in the project. The first subset contains only performed left or right hand motor tasks. The second subset contains only imagined left or right hand motor tasks. In both subsets, a total of 103 out of 109 subjects were used, and subjects 38, 88, 89, 92, 100, and 104 were omitted due to data annotation errors."}),"\n",(0,r.jsx)(n.h2,{id:"2--preprocessing-process",children:"2.  Preprocessing Process"}),"\n",(0,r.jsx)(n.p,{children:"The input data for each trial is split into (64, W) dimensions, where W represents the time dimension and 64 represents the number of channels. Because each trial of the execution and imagination tasks consisted of 4 to 4.1 seconds of continuous, sustained execution or imagination movement, all trials were truncated to contain exactly 4 seconds of data, sampled at 160 Hz, for a total of 640 samples to maintain a consistent dataset."}),"\n",(0,r.jsx)(n.p,{children:"Using the sliding window approach, the 640 samples in each trial were cut into eight non-overlapping Windows, each containing 80 samples. Each window was assigned the same target label as the original trial. Effectively increasing the size of the dataset by a factor of 8, providing more usable data."}),"\n",(0,r.jsxs)(n.p,{children:["Using Gumpy BCI signal processing module in the library (",(0,r.jsx)(n.a,{href:"https://www.mdpi.com/2073-431X/9/3/72#B21-computers-09-00072",children:"https://www.mdpi.com/2073-431X/9/3/72#B21-computers-09-00072"}),")] processing eeg signals. A notch filter was applied to the data to eliminate alternating current (AC) noise at 60 Hz frequency. The data were further band-pass filtered in the range of 2 Hz to 60 Hz with an order of 5."]}),"\n",(0,r.jsx)(n.h2,{id:"3-core-functions",children:"3. Core Functions"}),"\n",(0,r.jsx)(n.h4,{id:"31-load_data",children:"3.1 load_data()"}),"\n",(0,r.jsx)(n.p,{children:"load_data(nr_of_subj,trial_type,chunk_data,chunks,base_folder,processed_out_folder,sample_rate,samples,cpu_format,preprocessing,hp_freq,bp_low,bp_high,notch,hp_filter,bp_filter,artifact_removal)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),":Loads"," and preprocesses multi-subject electroencephalogram (EEG) data, supports band-pass/high-pass/notch filtering, artifact removal, and data slicing. Returns the preprocessed feature matrix and label array, and stores the preprocessed data in npz format (described in Section 4.4) in the folder specified by processed_out_folder."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inputs"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nr_of_subj"}),"\uff1a",(0,r.jsx)(n.code,{children:"int = 109"}),"\uff0cNumber of loaded subjects."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"trial_type"}),"\uff1a",(0,r.jsx)(n.code,{children:"int = 1"}),"\uff0cTrial type identification (e.g. ' Perform movement of type 1', ' imagine movement of type 2', ' perform movement and imagine movement of type 3') ."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"chunk_data"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether to split each trial into multiple chunks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"chunks"}),"\uff1a",(0,r.jsx)(n.code,{children:"int"})," = 8\uff0cNumber of chunks per trial, only if' chunk_data=True '."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"chunk_data"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether to split each trial into multiple chunks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"cpu_format"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether to format the output data into a Numpy array that can be processed by the CPU (possibly a GPU Tensor otherwise)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"preprocessing"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether to perform preprocessing (filtering, artifact removal, etc.)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"hp_freq"}),"\uff1a",(0,r.jsx)(n.code,{children:"float= 0.5"}),"\uff0cHigh pass filter cutoff frequency (Hz), only works if 'hp_filter=True'."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bp_low"}),"\uff1a",(0,r.jsx)(n.code,{children:"float= 2.0"}),"\uff0cBandpass filter low cutoff frequency (Hz), only works if 'bp_filter=True'."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bp_high"}),"\uff1a",(0,r.jsx)(n.code,{children:"float= 60.0"}),"\uff0cBandpass filter high cutoff frequency (Hz), only works if 'bp_filter=True'."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"notch"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether or not notch filtering (used to remove power interference such as 50Hz/60Hz) is enabled."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"hp_filter"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = False"}),"\uff0cWhether to perform high-pass filtering (overriding the' hp_freq 'setting)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bp_filter"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether to perform bandpass filtering (override 'bp_low' and 'bp_high' Settings)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"artifact_removal"}),"\uff1a",(0,r.jsx)(n.code,{children:"bool = True"}),"\uff0cWhether or not to do artifact removal."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"base_folder"}),"\uff1a",(0,r.jsx)(n.code,{children:'str= ""'}),"\uff0c The folder name where the dataset is located."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"processed_out_folder"}),"\uff1a",(0,r.jsx)(n.code,{children:'str= ""'}),"\uff0cThe name of the folder where the preprocessed dataset is located."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_rate"}),"\uff1a",(0,r.jsx)(n.code,{children:"int= 160"}),"\uff0cThe sample rate."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"samples"}),"\uff1a",(0,r.jsx)(n.code,{children:"int= 640"}),"\uff0c Sample points."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"outputs"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"all_features"}),"\uff1apreprocessed EEG feature data, usually of shape '(number of samples, number of channels, number of points in time)'."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"all_labels"}),"\uff1athe label of the corresponding example (number of examples, label), whether the movement is left or right hand'."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"4-usage",children:"4. Usage"}),"\n",(0,r.jsx)(n.h3,{id:"41-preparing--data",children:"4.1 Preparing  Data"}),"\n",(0,r.jsx)(n.p,{children:'Put the folder containing all the data in "base_folder".'}),"\n",(0,r.jsx)(n.h3,{id:"42-running-the-preprocessing-function-load_data",children:'4.2 Running the preprocessing function "load_data()"'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'python load_data(\n    nr_of_subj=109,\n    trial_type=1,\n    chunk_data=True,\n    chunks=8,\n    base_folder= "./data/",\n    processed_out_folder="./out_data/",\n    sample_rate=160,\n    samples=640,\n    cpu_format=False,\n    preprocessing= rue,\n    hp_freq=0.5,\n    bp_low=2.0,\n    bp_high=60.0,\n    notch=True,\n    hp_filter=False,\n    bp_filter=True,\n    artifact_removal=True\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:'By setting the "trial_type" value, you can get three types of pre-processed data. In addition, you can get different data pre-processed results according to the parameters you set.'}),"\n",(0,r.jsx)(n.h3,{id:"43-results-preview",children:"4.3 Results Preview"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\u251c\u2500\u2500 out_data/\n\u2502   \u251c\u2500\u2500 EMM_task1_preprocessed.npz    # Perform motion type preprocessing of the data\n\u2502   \u251c\u2500\u2500 EMM_task2_preprocessed.npz    # Preprocessed data for types of imagined movements\n\u2502   \u251c\u2500\u2500 EMM_task3_preprocessed.npz    # Perform preprocessed data for movement and imagination movement\n"})}),"\n",(0,r.jsx)(n.h3,{id:"44-load-the-preprocessed-data",children:"4.4 Load the preprocessed data"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import numpy as np\n\ndata = np.load('./out_data/EMM_task1_preprocessed.npz')\nfeatures = data['eeg']  # feature data of shape (number of samples, number of channels, number of time points)\nlabels = data['labels']  #  Feature data labels of shape (number of samples, labels), where labels represent left or right hand motion\n\nprint(features.shape, labels.shape)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>i});var t=s(6540);const r={},a=t.createContext(r);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);