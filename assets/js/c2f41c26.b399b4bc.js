"use strict";(self.webpackChunkhcihub_docs=self.webpackChunkhcihub_docs||[]).push([[8978],{4225:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"datasets/non-invasive/SEED IV","title":"4_SEED IV","description":"Dataset Link","source":"@site/docs/datasets/non-invasive/4_SEED IV.md","sourceDirName":"datasets/non-invasive","slug":"/datasets/non-invasive/SEED IV","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/SEED IV","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/datasets/non-invasive/4_SEED IV.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"3_EEGMMI","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/EEGMMI"},"next":{"title":"5_SEED-VII","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/SEED-VII"}}');var a=s(4848),t=s(8453);const r={},l="4_SEED IV",o={},d=[{value:"Dataset Link",id:"dataset-link",level:2},{value:"1. Experimental Design and Data Acquisition",id:"1-experimental-design-and-data-acquisition",level:3},{value:"2. Data Preprocessing Pipeline",id:"2-data-preprocessing-pipeline",level:3},{value:"EEG Signal Preprocessing",id:"eeg-signal-preprocessing",level:4},{value:"3. Labels and Synchronization",id:"3-labels-and-synchronization",level:3},{value:"4. Data Loading Example",id:"4-data-loading-example",level:3},{value:"5. Return Values",id:"5-return-values",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"4_seed-iv",children:"4_SEED IV"})}),"\n",(0,a.jsx)(n.h1,{id:"overview-and-processing-pipeline",children:"Overview and Processing Pipeline"}),"\n",(0,a.jsx)(n.h2,{id:"dataset-link",children:"Dataset Link"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://bcmi.sjtu.edu.cn/~seed/seed-iv.html",children:"SEED-IV Dataset Official Website"})}),"\n",(0,a.jsx)(n.h3,{id:"1-experimental-design-and-data-acquisition",children:"1. Experimental Design and Data Acquisition"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Participants:"})," 15 subjects, each performing 3 sessions on different days."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Trials:"})," Each session contains 24 trials; in each trial, participants watch a film clip designed to evoke one of four emotions: happiness, sadness, fear, or neutral."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Equipment:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"62-channel ESI NeuroScan EEG system (for EEG signals)"}),"\n",(0,a.jsx)(n.li,{children:"SMI eye-tracking glasses (for eye movement data)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"2-data-preprocessing-pipeline",children:"2. Data Preprocessing Pipeline"}),"\n",(0,a.jsx)(n.h4,{id:"eeg-signal-preprocessing",children:"EEG Signal Preprocessing"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Downsampling"}),"\r\nResample the original EEG data to a uniform sampling rate of 200 Hz."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bandpass Filtering"}),"\r\nApply a 1 Hz to 75 Hz bandpass filter to remove noise and artifacts."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Feature Extraction"}),"\r\nCompute the power spectral density (PSD) and differential entropy (DE) over 5 frequency bands (delta, theta, alpha, beta, gamma) for non-overlapping 4-second segments."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Feature Smoothing"}),"\r\nReduce noise using moving average or linear dynamic system filtering methods."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"3-labels-and-synchronization",children:"3. Labels and Synchronization"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Each trial is labeled with the emotion category of the corresponding film clip (happy, sad, fear, neutral)."}),"\n",(0,a.jsx)(n.li,{children:"The time windows of the data are aligned with labels; each 4-second segment corresponds to one sample."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"4-data-loading-example",children:"4. Data Loading Example"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'python\u590d\u5236\u7f16\u8f91def load_data(session_id, sub_id):\r\n    """\r\n    Load a .npz data file for a specific session and subject ID.\r\n\r\n    :param session_id: int, optional, default=1\r\n        The session number, corresponding to the folder named "session{session_id}".\r\n    :param sub_id: int, optional, default=1\r\n        The subject ID used to filter files starting with "{sub_id}_".\r\n    :return: numpy.lib.npyio.NpzFile or None\r\n        The loaded npz file object if found; otherwise None.\r\n    """\r\n    for file in os.listdir(f"session{session_id}"):\r\n        if file.startswith(f\'{sub_id}_\') and file.endswith(\'.npz\'):\r\n            print(f"Loading data from: {file} (session={session_id})")\r\n            return np.load(os.path.join(f"session{session_id}", file), allow_pickle=True)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"5-return-values",children:"5. Return Values"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:".npz"})," files contain two arrays named ",(0,a.jsx)(n.code,{children:"'features'"})," and ",(0,a.jsx)(n.code,{children:"'labels'"}),", which store the sample features and labels, respectively."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"features"})," is a 3D array representing multiple samples, with dimensions typically corresponding to samples \xd7 channels \xd7 frequency bands."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"labels"})," is a 1D array containing the emotion label for each sample."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>l});var i=s(6540);const a={},t=i.createContext(a);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);