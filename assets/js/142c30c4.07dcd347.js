"use strict";(self.webpackChunkhcihub_docs=self.webpackChunkhcihub_docs||[]).push([[2617],{548:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"datasets/non-invasive/Things EEG","title":"6_Things EEG","description":"Dataset Link\uff1a","source":"@site/docs/datasets/non-invasive/6_Things EEG.md","sourceDirName":"datasets/non-invasive","slug":"/datasets/non-invasive/Things EEG","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/Things EEG","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/datasets/non-invasive/6_Things EEG.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"5_SEED-VII","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/SEED-VII"},"next":{"title":"7_Calcium Imaging","permalink":"/BCIJelly-site/docs/next/datasets/non-invasive/Calcium Imaging"}}');var t=s(4848),a=s(8453);const r={},d="6_Things EEG",o={},c=[{value:"Dataset Link\uff1a",id:"dataset-link",level:2},{value:"1. Project Overview",id:"1-project-overview",level:2},{value:"2.  Preprocessing Procedure",id:"2--preprocessing-procedure",level:2},{value:"3. Core Functions",id:"3-core-functions",level:2},{value:"3.1 epoching ()",id:"31-epoching-",level:4},{value:"3.2 mvnn()",id:"32-mvnn",level:4},{value:"4. Usage",id:"4-usage",level:2},{value:"4.1 Prepare Data",id:"41-prepare-data",level:3},{value:"4.2 Run Preprocessing Scripts",id:"42-run-preprocessing-scripts",level:3},{value:"4.3 Output Preview",id:"43-output-preview",level:3},{value:"4.4 Load Preprocessed Data",id:"44-load-preprocessed-data",level:3}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"6_things-eeg",children:"6_Things EEG"})}),"\n",(0,t.jsx)(n.h1,{id:"overview-and-processing-pipeline",children:"Overview and Processing Pipeline"}),"\n",(0,t.jsx)(n.h2,{id:"dataset-link",children:"Dataset Link\uff1a"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://osf.io/crxs4/",children:"https://osf.io/crxs4/"})}),"\n",(0,t.jsx)(n.h2,{id:"1-project-overview",children:"1. Project Overview"}),"\n",(0,t.jsxs)(n.p,{children:["This project provides a preprocessing method for the THINGS-EEG dataset, transforming raw EEG signals into model-ready data. The dataset contains high-temporal-resolution EEG responses from ",(0,t.jsx)(n.strong,{children:"10 participants"})," to naturalistic object images, recorded using a Rapid Serial Visual Presentation (RSVP) paradigm.\nEach participant completed ",(0,t.jsx)(n.strong,{children:"82,160 trials"}),", covering ",(0,t.jsx)(n.strong,{children:"16,740 image conditions"}),".\nThe training set consists of ",(0,t.jsx)(n.strong,{children:"16,540 (image categories) \xd7 10 (images per category) \xd7 4 (repetitions)"}),", and the test set contains ",(0,t.jsx)(n.strong,{children:"200 (image categories) \xd7 1 (image) \xd7 80 (repetitions)"}),". Training and test stimuli were presented in a pseudo-random order, and target images were used to reduce blinking and other artifacts. EEG was recorded with a ",(0,t.jsx)(n.strong,{children:"64-channel EASYCAP"})," (electrodes arranged according to the standard 10\u201310 system) and a ",(0,t.jsx)(n.strong,{children:"BrainVision actiCHamp amplifier"})," at ",(0,t.jsx)(n.strong,{children:"1000 Hz"})," sampling rate, with online filtering (0.1\u2013100 Hz) and referencing to the Fz electrode."]}),"\n",(0,t.jsx)(n.h2,{id:"2--preprocessing-procedure",children:"2.  Preprocessing Procedure"}),"\n",(0,t.jsxs)(n.p,{children:["EEG data was segmented into trials from ",(0,t.jsx)(n.strong,{children:"0 to 1000 ms"})," after stimulus onset. Baseline correction was applied using the ",(0,t.jsx)(n.strong,{children:"200 ms pre-stimulus period"}),". All channels were downsampled to ",(0,t.jsx)(n.strong,{children:"250 Hz"})," for analysis, and multivariate noise normalization (MVNN) was applied. The EEG responses for all repetitions were averaged to improve the signal-to-noise ratio, and the effect of the number of repetitions was also analyzed.\nImages were resized to ",(0,t.jsx)(n.strong,{children:"224\xd7224"})," and normalized before being processed by an image encoder. The ",(0,t.jsx)(n.strong,{children:"CLIP (Contrastive Language-Image Pretraining)"})," model was used to extract pretrained image features."]}),"\n",(0,t.jsx)(n.h2,{id:"3-core-functions",children:"3. Core Functions"}),"\n",(0,t.jsx)(n.h4,{id:"31-epoching-",children:"3.1 epoching ()"}),"\n",(0,t.jsx)(n.p,{children:"epoching(args, data_part, seed)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Function"}),":  Converts raw EEG data to MNE format, performs channel selection, epoching, baseline correction, and downsampling. The EEG data is classified and sorted according to image conditions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input Parameters"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"args"}),": Namespace containing experimental configuration (e.g., sampling rate ",(0,t.jsx)(n.code,{children:"sfreq"}),", subject number ",(0,t.jsx)(n.code,{children:"sub"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"data_part"}),": ",(0,t.jsx)(n.code,{children:"str"}),", data partition (",(0,t.jsx)(n.code,{children:"'test'"})," or ",(0,t.jsx)(n.code,{children:"'training'"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"seed"}),": ",(0,t.jsx)(n.code,{children:"int"}),", random seed for reproducibility."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"epoched_data"}),": ",(0,t.jsx)(n.code,{children:"List[float]"}),", epoched EEG data sorted by image conditions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"img_conditions"}),": ",(0,t.jsx)(n.code,{children:"List[int]"}),", unique image condition labels."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"ch_names"}),": ",(0,t.jsx)(n.code,{children:"List[str]"}),", EEG channel names."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"times"}),": ",(0,t.jsx)(n.code,{children:"float"}),", EEG time points (relative to stimulus onset)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"32-mvnn",children:"3.2 mvnn()"}),"\n",(0,t.jsx)(n.p,{children:"mvnn(args, epoched_test, epoched_train)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Function"}),": Computes the covariance matrix of EEG data (averaged over time points or trials), calculates the inverse square root (whitening matrix), and applies it to the test and training EEG data to remove channel correlations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input Parameters"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"args"}),": Namespace containing configuration parameters (e.g., ",(0,t.jsx)(n.code,{children:"mvnn_dim"})," specifying covariance computation dimension)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"epoched_test"}),": ",(0,t.jsx)(n.code,{children:"List[float]"}),", epoched EEG test data (shape: ",(0,t.jsx)(n.code,{children:"[conditions \xd7 repetitions \xd7 channels \xd7 time]"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"epoched_train"}),": ",(0,t.jsx)(n.code,{children:"List[float]"}),", epoched EEG training data (shape: ",(0,t.jsx)(n.code,{children:"[conditions \xd7 repetitions \xd7 channels \xd7 time]"}),")."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"whitened_test"}),": ",(0,t.jsx)(n.code,{children:"List[float]"}),", whitened EEG test data (same shape as input)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"whitened_train"}),": ",(0,t.jsx)(n.code,{children:"List[float]"}),", whitened EEG training data (same shape as input)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4-usage",children:"4. Usage"}),"\n",(0,t.jsx)(n.h3,{id:"41-prepare-data",children:"4.1 Prepare Data"}),"\n",(0,t.jsxs)(n.p,{children:["Place all files from the dataset's ",(0,t.jsx)(n.strong,{children:"Raw EEG data"})," and ",(0,t.jsx)(n.strong,{children:"Image set"})," folders into the directory specified by the ",(0,t.jsx)(n.code,{children:"project_dir"})," variable in ",(0,t.jsx)(n.code,{children:"processing.py"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"42-run-preprocessing-scripts",children:"4.2 Run Preprocessing Scripts"}),"\n",(0,t.jsxs)(n.p,{children:["First, run ",(0,t.jsx)(n.code,{children:"processing.py"})," to obtain preprocessed EEG data (in ",(0,t.jsx)(n.code,{children:".npy"})," format). The data will be saved to ",(0,t.jsx)(n.code,{children:"project_dir/Preprocessed_data_250Hz"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python processing.py\n# Specify the subject (sub) and the dataset save directory (project_dir)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Next, run ",(0,t.jsx)(n.code,{children:"obtain_feature_maps_clip.py"})," to extract pretrained image features (in ",(0,t.jsx)(n.code,{children:".npy"})," format) using the CLIP model. The features will be saved to ",(0,t.jsx)(n.code,{children:"out_data"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python obtain_feature_maps_clip.py\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Finally, run ",(0,t.jsx)(n.code,{children:"processed.py"})," to generate the final preprocessed dataset files (in ",(0,t.jsx)(n.code,{children:".npz"})," format). You need to specify the paths to the preprocessed EEG data and image features (",(0,t.jsx)(n.code,{children:"project_dir"}),") as well as the output save path (",(0,t.jsx)(n.code,{children:"out_data"}),")."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python processed.py\n"})}),"\n",(0,t.jsx)(n.h3,{id:"43-output-preview",children:"4.3 Output Preview"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u251c\u2500\u2500 out_data/\n\u2502   \u251c\u2500\u2500 sub01\n\u2502   \u2502   \u251c\u2500\u2500 preprocessed_eeg_training.npz  # Preprocessed EEG training data\n\u2502   \u2502   \u251c\u2500\u2500 preprocessed_eeg_test.npz      # Preprocessed EEG test data\n\u2502   \u2502   \u251c\u2500\u2500 clip_feature_maps_training.npz # CLIP-pretrained image features for training set\n\u2502   \u2502   \u251c\u2500\u2500 clip_feature_maps_test.npz     # CLIP-pretrained image features for test set\n\u2502   \u251c\u2500\u2500 sub02\n"})}),"\n",(0,t.jsx)(n.h3,{id:"44-load-preprocessed-data",children:"4.4 Load Preprocessed Data"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import numpy as np\n\n# Load EEG training data\ndata = np.load('./out_data/sub01/preprocessed_eeg_training.npz')\nfeatures = data['eeg']      # Shape: (samples, channels, time points)\nlabels = data['labels']     # Shape: (samples,), labels represent image categories\n\n# Load image feature training data\ndata = np.load('./out_data/sub01/clip_feature_maps_training.npz')\nfeatures_image = data['image_feature']  # Shape: (samples, features)\nlabels_image = data['labels']           # Shape: (samples,), labels represent image categories\n\nprint(features.shape, labels.shape)\nprint(features_image.shape, labels_image.shape)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>d});var i=s(6540);const t={},a=i.createContext(t);function r(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);