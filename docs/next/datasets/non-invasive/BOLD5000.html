<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-datasets/non-invasive/BOLD5000" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">1_BOLD5000 | BCIJelly</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bcihub.github.io/BCIJelly-site/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://bcihub.github.io/BCIJelly-site/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://bcihub.github.io/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="1_BOLD5000 | BCIJelly"><meta data-rh="true" name="description" content="Dataset Link"><meta data-rh="true" property="og:description" content="Dataset Link"><link data-rh="true" rel="icon" href="/BCIJelly-site/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://bcihub.github.io/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000"><link data-rh="true" rel="alternate" href="https://bcihub.github.io/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000" hreflang="en"><link data-rh="true" rel="alternate" href="https://bcihub.github.io/BCIJelly-site/zh/docs/next/datasets/non-invasive/BOLD5000" hreflang="zh"><link data-rh="true" rel="alternate" href="https://bcihub.github.io/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"1_BOLD5000","item":"https://bcihub.github.io/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000"}]}</script><link rel="alternate" type="application/rss+xml" href="/BCIJelly-site/blog/rss.xml" title="BCIJelly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/BCIJelly-site/blog/atom.xml" title="BCIJelly Atom Feed"><link rel="stylesheet" href="/BCIJelly-site/assets/css/styles.1c46aeb9.css">
<script src="/BCIJelly-site/assets/js/runtime~main.524899e4.js" defer="defer"></script>
<script src="/BCIJelly-site/assets/js/main.44c57978.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/BCIJelly-site/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/BCIJelly-site/"><div class="navbar__logo"><img src="/BCIJelly-site/img/logo.svg" alt="BCIJelly Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/BCIJelly-site/img/logo.svg" alt="BCIJelly Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">BCIJelly</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/BCIJelly-site/docs/next/datasets/invasive/FALCON M1-A">Tutorial</a><a class="navbar__item navbar__link" href="/BCIJelly-site/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000">Next</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000">Next</a></li><li><a class="dropdown__link" href="/BCIJelly-site/docs/intro">1.2.0</a></li><li><a class="dropdown__link" href="/BCIJelly-site/docs/1.1.0/intro">1.1.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/BCIJelly-site/zh/docs/next/datasets/non-invasive/BOLD5000" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh">中文</a></li></ul></div><a href="https://github.com/bcihub/BCIJelly-site" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/BCIJelly-site/docs/next/datasets/invasive/FALCON M1-A">datasets</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/BCIJelly-site/docs/next/datasets/invasive/FALCON M1-A">invasive</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000">non-invasive</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/BOLD5000">1_BOLD5000</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/GOD">2_GOD</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/EEGMMI">3_EEGMMI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/SEED IV">4_SEED IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/SEED-VII">5_SEED-VII</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/Things EEG">6_Things EEG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/BCIJelly-site/docs/next/datasets/non-invasive/Calcium Imaging">7_Calcium Imaging</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/BCIJelly-site/docs/next/models/CCA">models</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for <!-- -->BCIJelly<!-- --> <b>Next</b> version.</div><div class="margin-top--md">For up-to-date documentation, see the <b><a href="/BCIJelly-site/docs/intro">latest version</a></b> (<!-- -->1.2.0<!-- -->).</div></div><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/BCIJelly-site/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">datasets</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">non-invasive</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">1_BOLD5000</span></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: Next</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>1_BOLD5000</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-link">Dataset Link<a href="#dataset-link" class="hash-link" aria-label="Direct link to Dataset Link" title="Direct link to Dataset Link">​</a></h2>
<p><a href="https://bold5000-dataset.github.io/website/download.html" target="_blank" rel="noopener noreferrer">BOLD5000</a></p>
<h1>I. Project Background</h1>
<p>This project aims to conduct standardized preprocessing on the BOLD5000 dataset, extract fMRI features and perform dimensionality transformation, providing high-quality input features and corresponding labels for subsequent model training related to visual cognition (such as image classification, brain activity prediction, etc.).</p>
<h1>II. Data Processing</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-fmri-time-series-extraction">1. fMRI Time Series Extraction<a href="#1-fmri-time-series-extraction" class="hash-link" aria-label="Direct link to 1. fMRI Time Series Extraction" title="Direct link to 1. fMRI Time Series Extraction">​</a></h2>
<p>The time series data of all voxels in the ROIs provided in the dataset release 2.0 version (<a href="https://figshare.com/s/bbaf45dca1b1b873ddfa" target="_blank" rel="noopener noreferrer">BOLD5000 Release 2.0</a>) after GLM analysis are directly used as fMRI features (folder BOLD5000_GLMsingle_ROI_betas).</p>
<p>This data has undergone the following process: [See the article <strong>BOLD5000</strong> A public fMRI dataset of 5000 images]</p>
<ol>
<li>
<p>Preprocessing</p>
<p>All the original fMRI data have been processed through the standardized pipeline using <strong>fMRIPREP 1.1.4</strong>, including:</p>
<ul>
<li>Motion correction, slice timing correction, geometric distortion correction</li>
<li>Functional-anatomical registration, MNI152NLin2009cAsym spatial normalization</li>
<li>Regression of 9 nuisance variables (6 motion parameters + CSF/WM/global signal)</li>
<li>128 s high-pass filtering</li>
</ul>
</li>
<li>
<p>Functional Localizer Analysis</p>
<ul>
<li>
<p>On 8 (or 6) localizer runs, use SPM12 to establish a GLM and run the following contrasts:</p>
<ul>
<li>Scene &gt; Object &amp; Scrambled →<strong>PPA, RSC, OPA</strong></li>
<li>Object &gt; Scrambled → <strong>LOC</strong></li>
<li>Scrambled &gt; Baseline → <strong>EarlyVis</strong></li>
</ul>
</li>
<li>
<p>FWE correction (p &lt; 0.0001, k ≥ 30) was applied to the significant voxels to obtain individual spatial binary ROI masks, which were then resampled to the MNI voxel grid.</p>
</li>
<li>
<p>The time window was averaged (based on the peak activation of ROI signals).</p>
<ul>
<li>CSI1-3: average of TR3 + TR4 (4 - 8 s)</li>
<li>CSI4: only TR3 (4 - 6 s)</li>
</ul>
</li>
<li>
<p>Signal extraction: the time series of all voxels within each ROI, demeaned.</p>
</li>
</ul>
</li>
<li>
<p>Main Experiment Single Trial GLM Modeling</p>
<ul>
<li>
<p>On the preprocessed main experimental data, a GLM-single-trial (LS-S) model was established for each stimulus image one by one:</p>
<ul>
<li>Each stimulus image corresponds to a regressor (stick function, 1 s ON, 9 s OFF).</li>
<li>The same 9 nuisance regressors, run regressors, and 128 s high-pass filtering were again included.</li>
</ul>
</li>
<li>
<p>For each voxel within the ROI mask, the β coefficient (event-related amplitude) of this image at this voxel was solved.</p>
</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-tags-based-on-eventstsv">2. <strong>Tags (Based on events.tsv)</strong><a href="#2-tags-based-on-eventstsv" class="hash-link" aria-label="Direct link to 2-tags-based-on-eventstsv" title="Direct link to 2-tags-based-on-eventstsv">​</a></h2>
<p>The labels can be directly read from the event.csv file in the dataset.</p>
<p>Each fMRI run has a corresponding <code>events.tsv</code> file, with fields including:</p>
<ul>
<li><code>onset</code>: The time point when the image appears.</li>
<li><code>duration</code>: Usually 1 second (the time the image is presented).</li>
<li><code>trial_type</code>: Fixed as <code>stimulus</code>.</li>
<li><code>stimulus</code>: The file name of the image.</li>
<li><code>ImgID</code>: The unique ID of the image (used for pairing image features).</li>
<li><code>ImgType</code>: The type of the image (ImageNet, coco, scenes).</li>
</ul>
<p>The tag processing method is as follows:</p>
<ol>
<li>Extract the image type labels (ImgType) from the event.csv file and perform standardization processing. Standardization refers to classifying the rep category (repeated occurrences) and non-rep into one category.</li>
<li>Convert the string format labels into numerical format acceptable by machine learning models.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-1d-time-series-to-2d-features-based-on-gaf-method">3. 1D Time Series to 2D Features (Based on GAF Method)<a href="#3-1d-time-series-to-2d-features-based-on-gaf-method" class="hash-link" aria-label="Direct link to 3. 1D Time Series to 2D Features (Based on GAF Method)" title="Direct link to 3. 1D Time Series to 2D Features (Based on GAF Method)">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="overall-process-reference-1">Overall Process (Reference [1]):<a href="#overall-process-reference-1" class="hash-link" aria-label="Direct link to Overall Process (Reference [1]):" title="Direct link to Overall Process (Reference [1]):">​</a></h3>
<ol>
<li>
<p><strong>Time Series Extraction</strong>
Complete time series are extracted from each fMRI run and each active voxel, representing the distribution of BOLD signal intensity over time. As each run contains 37 visual stimuli (images), the length of the time series is 37.</p>
</li>
<li>
<p><strong>Time Series Segmentation</strong>
The complete time series is segmented into three parts based on the dataset (COCO, ImageNet, SUN) to which the images presented in each trial belong, corresponding to the BOLD signals during the viewing of the three types of images.</p>
</li>
<li>
<p><strong>Preprocessing</strong>
Linear interpolation is applied to the voxel-specific time series after segmentation to uniformly adjust them to the same time length, in order to meet the requirements of subsequent analysis.</p>
</li>
<li>
<p><strong>Conversion from 1D Time Series to 2D Spatial Features</strong></p>
<p>The 1D time series is transformed into a 2D matrix through Gramian Angular Field (GAF) to capture the spatial correlation features within the time series.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="core-principles-of-gaf">Core Principles of GAF<a href="#core-principles-of-gaf" class="hash-link" aria-label="Direct link to Core Principles of GAF" title="Direct link to Core Principles of GAF">​</a></h3>
<p><strong>Gramian Angular Field (GAF)</strong>: Through polar coordinate transformation, the normalized time series is mapped to a 2D matrix to generate Gramian Angular Summation Field (GASF) and Gramian Angular Difference Field (GADF), preserving time dependency without information loss.</p>
<p>Specific Steps</p>
<p>(1) Data Normalization</p>
<p>Normalize a 1D time series (with length <code>T</code>) to the range <code>[-1, 1]</code>. The formula is:</p>
<p>Run Python</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">x_norm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token builtin">min</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token builtin">min</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><br></span></code></pre></div></div>
<p>Among them, <code>x</code> represents the original time series, and <code>x_norm</code> is the normalized result.</p>
<p>(2) Polar Coordinate Transformation</p>
<p>Map the normalized sequence to polar coordinates <code>(r, θ)</code>:</p>
<ul>
<li>Angle <code>θ</code>: Calculated from <code>x_norm</code> as <code>θ = arccos(x_norm)</code> (since <code>x_norm ∈ [-1, 1]</code>, <code>θ ∈ [0, π]</code>);</li>
<li>Radius <code>r</code>: Normalized from the time step, <code>r = t / T</code> (<code>t</code> is the time index, <code>t ∈ [0, T-1]</code>).</li>
</ul>
<p>(3) Calculation of GASF and GADF</p>
<ul>
<li><strong>GASF</strong>: <code>GASF[i, j] = cos(θ_i + θ_j)</code></li>
<li><strong>GADF</strong>: <code>GADF[i, j] = sin(θ_i - θ_j)</code></li>
</ul>
<p>Here, <code>i</code> and <code>j</code> are matrix indices, and <code>θ_i</code> and <code>θ_j</code> are the angles at the <code>i</code>th and <code>j</code>th time steps, respectively.</p>
<h1>III. Main Function Descriptions</h1>
<p>The main function of the <code>mark_img</code> function is to convert time series data into image data suitable for input into a convolutional neural network (CNN), as detailed below:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">mark_img</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dat</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	gram </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> GramianAngularField</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> method</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;summation&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token comment" style="color:#999988;font-style:italic">##change method=&#x27;difference&#x27; for GramianAngularField difference</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	gram_t </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> gram</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">iloc</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">,</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> gram_t</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">reshape</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">gram_t</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> y</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">dat</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;label&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	</span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">y</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="function-analysis">Function Analysis:<a href="#function-analysis" class="hash-link" aria-label="Direct link to Function Analysis:" title="Direct link to Function Analysis:">​</a></h3>
<ol>
<li><strong>Core Tools for Converting Time Series to Images</strong>
The <code>GramianAngularField</code> algorithm in the <code>pyts.image</code> library is used to convert time series data into images. This is a common technique for handling time series data, which can preserve the temporal correlation and amplitude information of the time series.</li>
<li><strong>Parameter Description</strong></li>
</ol>
<ul>
<li><code>GramianAngularField(image_size=16, method=&#x27;summation&#x27;)</code>: Generates a 16x16 image, with the conversion method set to <code>summation</code>. It can also be changed to <code>difference</code>.</li>
<li><code>dat</code>: The input DataFrame, where the last column is the label (<code>label</code>), and the remaining columns are the time series feature data.</li>
<li>Parameter <code>16</code> is specified for the article, mainly based on the experimental design corresponding to the dataset itself.</li>
</ul>
<ol start="3">
<li><strong>Data Processing Steps</strong></li>
</ol>
<ul>
<li>Extract the time series features from the input data except for the last column (the label column) as <code>dat.iloc[:,:-1]</code>.</li>
<li>Obtain the image data <code>gram_t</code> through Gramian Angular Field transformation, with a shape of <code>(number of samples, 16, 16)</code>.</li>
<li>Reshape the image data to the input format required by CNN, which is <code>(number of samples, 16, 16, 1)</code> (the last dimension represents the number of channels, and here it is a single-channel grayscale image).</li>
<li>Extract the label column <code>dat[&#x27;label&#x27;]</code> as the target variable <code>y</code>.</li>
</ul>
<ol start="4">
<li><strong>Return Values</strong></li>
</ol>
<ul>
<li><code>x</code>: The transformed image data (shape: <code>(n_samples, 16, 16, 1)</code>).</li>
<li><code>y</code>: The corresponding label data, used as the target value for model training.</li>
</ul>
<p>This function realizes the conversion from one-dimensional time series to two-dimensional images, preparing for the subsequent deep learning classification tasks.</p>
<h1>IV. Instructions for Use</h1>
<p>Data is stored on a per-subject basis (supporting direct training with data from individual subjects).</p>
<p>Usage method:</p>
<ol>
<li>Directly load the <code>.npz</code> format file through the <code>np.load</code> function.</li>
<li>After loading, the corresponding data can be obtained through the two keywords <code>fmri</code> and <code>label</code>:</li>
</ol>
<ul>
<li>
<p><code>fmri</code>: fMRI two-dimensional image data, with a shape of <code>(trials, height, weight)</code>, where both height and weight are 16.</p>
</li>
<li>
<p><code>label</code>: Label data, containing three values: 0, 1, and 2, which respectively correspond to:</p>
<ul>
<li>
<p>0: coco category</p>
</li>
<li>
<p>1: imagenet category</p>
</li>
<li>
<p>2: scenes category</p>
<p>The ratio of the three types of labels is 2:2:1.</p>
</li>
</ul>
</li>
</ul>
<h1>V. Notes to Observe</h1>
<p>The current data is based on the signals of all voxels within the ROIs (regions of interest) (refer to Article [1]). In practical analysis, in addition to using the signals of all voxels, it is also possible to consider performing dimensionality reduction on each ROI separately before conducting subsequent analysis.</p>
<h1>References</h1>
<ol>
<li>V. K. Kancharala, D. Bhattacharya and N. Sinha, &quot;Spatial Encoding of BOLD fMRI Time Series for Categorizing Static Images Across Visual Datasets: A Pilot Study on Human Vision,&quot; TENCON 2023 - 2023 IEEE Region 10 Conference (TENCON), Chiang Mai, Thailand, 2023, pp. 1117-1122, doi: 10.1109/TENCON58879.2023.10322476.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/datasets/non-invasive/1_BOLD5000.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/BCIJelly-site/docs/next/datasets/invasive/Emotion"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">13_Emotion</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/BCIJelly-site/docs/next/datasets/non-invasive/GOD"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">2_GOD</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#dataset-link" class="table-of-contents__link toc-highlight">Dataset Link</a></li><li><a href="#1-fmri-time-series-extraction" class="table-of-contents__link toc-highlight">1. fMRI Time Series Extraction</a></li><li><a href="#2-tags-based-on-eventstsv" class="table-of-contents__link toc-highlight">2. <strong>Tags (Based on events.tsv)</strong></a></li><li><a href="#3-1d-time-series-to-2d-features-based-on-gaf-method" class="table-of-contents__link toc-highlight">3. 1D Time Series to 2D Features (Based on GAF Method)</a><ul><li><a href="#overall-process-reference-1" class="table-of-contents__link toc-highlight">Overall Process (Reference [1]):</a></li><li><a href="#core-principles-of-gaf" class="table-of-contents__link toc-highlight">Core Principles of GAF</a></li><li><a href="#function-analysis" class="table-of-contents__link toc-highlight">Function Analysis:</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/BCIJelly-site/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/BCIJelly-site/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>